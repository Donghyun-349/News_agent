"""ë¯¸êµ­ ë¶€ë™ì‚° ì‹œìž¥ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° (Google News RSS ì‚¬ìš©)"""

from typing import List, Dict, Any, Optional
import logging
import os

from src.collectors.google_news_rss import GoogleNewsRSSScraper
from config.settings import MIN_ARTICLES_PER_SOURCE, US_REAL_ESTATE_TARGET_COUNT
from src.utils.config_loader import config_loader

logger = logging.getLogger(__name__)


class USRealEstateScraper(GoogleNewsRSSScraper):
    """ë¯¸êµ­ ë¶€ë™ì‚° ì‹œìž¥ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° (Google News RSS ì‚¬ìš©)"""
    
    # ì¿¼ë¦¬ëŠ” config.jsonì—ì„œ ë¡œë“œë©ë‹ˆë‹¤.
    
    def __init__(self, topic: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            topic: ìˆ˜ì§‘í•  ì£¼ì œëª… (Noneì´ë©´ ëª¨ë“  ì£¼ì œ ìˆ˜ì§‘)
        """
        # Dynamic Config Load
        self.queries = config_loader.get_queries("US Real Estate") or {}
        target_count = config_loader.get_setting("us_real_estate_target_count", US_REAL_ESTATE_TARGET_COUNT)
        
        max_workers = int(os.getenv("US_REAL_ESTATE_MAX_WORKERS", "5"))
        
        super().__init__(
            source_name="US Real Estate",
            queries=self.queries,
            target_count=target_count,
            max_workers=max_workers
        )
        self.topic = topic
    
    def _process_topic_articles(self, topic_name: str, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ì£¼ì œë³„ ê¸°ì‚¬ë“¤ì„ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤ (ì†ŒìŠ¤ ì¶”ê°€, topic í•„ë“œ ì¶”ê°€).
        US Real EstateëŠ” ìŠ¤ë‹ˆíŽ«ì„ ìˆ˜ì§‘í•˜ì§€ ì•Šë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Args:
            topic_name: ì£¼ì œëª…
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì²˜ë¦¬ëœ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        """
        # newspaper3kë¥¼ í™œìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ê°• (ìŠ¤ë‹ˆíŽ« ì œì™¸)
        processed_articles = self._process_articles(
            articles,
            skip_enrichment=False,  # newspaper3k ë³´ê°• í™œì„±í™”
            clear_summary=True      # ìŠ¤ë‹ˆíŽ« ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ
        )
        
        # ì†ŒìŠ¤ ì´ë¦„ì„ ë°œí–‰ ì–¸ë¡ ì‚¬ë¡œ ì„¤ì • (ì—†ìœ¼ë©´ ì£¼ì œëª…)
        for article in processed_articles:
            # topic í•„ë“œ ì¶”ê°€
            article["topic"] = topic_name
            press_name = article.get("press_name", "")
            if press_name:
                article["source"] = press_name
            else:
                article["source"] = topic_name
            
            # ì¹´í…Œê³ ë¦¬ ì¶”ê°€
            article = self._add_content_category(
                article,
                category="real_estate",
                source_type="foreign"
            )
        
        return processed_articles
    

    def fetch_news(self) -> List[Dict[str, Any]]:
        """
        ë¯¸êµ­ ë¶€ë™ì‚° ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        íŠ¹ì • ì£¼ì œê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ì£¼ì œë§Œ, ì•„ë‹ˆë©´ ëª¨ë“  ì£¼ì œ ìˆ˜ì§‘.
        
        **Sampling Logic**:
        ìˆ˜ì§‘ëœ ì „ì²´ ê¸°ì‚¬ ì¤‘ ì•½ 1/3 (33%)ë§Œ ë¬´ìž‘ìœ„ë¡œ ìƒ˜í”Œë§í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        ë‹¨, ì£¼ì œë³„ ë¶ˆê· í˜•ì„ ë§‰ê¸° ìœ„í•´ Stratified Sampling(ì£¼ì œë³„ ìƒ˜í”Œë§)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Returns:
            ê¸°ì‚¬ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        import random
        from collections import defaultdict

        # ìˆ˜ì§‘í•  ì£¼ì œ ëª©ë¡
        topics = [self.topic] if self.topic else list(self.queries.keys())
        
        # 1. ë¶€ëª¨ í´ëž˜ìŠ¤ì˜ fetch_news ì‚¬ìš©í•˜ì—¬ ì „ì²´ ìˆ˜ì§‘ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        full_articles = super().fetch_news(selected_topics=topics)
        
        logger.info(f"ðŸ“Š Before Sampling: {len(full_articles)} articles collected.")
        
        # 2. ì£¼ì œë³„ë¡œ ê·¸ë£¹í™” (Stratified Sampling ì¤€ë¹„)
        grouped_articles = defaultdict(list)
        for article in full_articles:
            # article["topic"]ì€ _process_topic_articlesì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
            t = article.get("topic", "Unknown")
            grouped_articles[t].append(article)
            
        # 3. ì£¼ì œë³„ 1/3 ìƒ˜í”Œë§
        sampled_results = []
        for t, items in grouped_articles.items():
            count = len(items)
            # Sampling Logic Removed (100% Selection)
            # ìµœì†Œ 1ê°œëŠ” ìœ ì§€í•˜ë˜, ë¹„ìœ¨ëŒ€ë¡œ ê³„ì‚° -> ì „ì²´ ì„ íƒ
            target_n = count
            
            # ì „ì²´ ì„ íƒ
            selected = items
            sampled_results.extend(selected)
            logger.info(f"  - Topic '{t}': {count} -> {len(selected)} (target: {target_n})")
            
        logger.info(f"âœ… After Stratified Sampling: {len(sampled_results)} articles final result.")
        
        return sampled_results

